This chapter explores previous approaches to parallelism in a
functional language, both implicit and explicit. We do this so that
we may better understand the trade-offs we accept when utilising
implicit parallelism and the difficulties involved.

\subsection*{Plan of the Chapter}

The chapter is organised as follows. We begin in Section \ref{sec:shortHistory}
by giving a brief overview of the history of graph reduction as a method for
the execution of functional programs. Section \ref{sec:FPandPar} discusses the
benefits that functional languages provide for parallelisation; we will focus
on call-by-need (or lazy) semantics. We then explore the various methods for
the \emph{implementation} of lazy languages for sequential machines in Section
\ref{sec:SequentialMachines}. Understanding how lazy languages can be executed
we will then show in Section \ref{sec:ParallelMachines} how the techniques can
be extended to allow for parallel execution\footnote{One of the nice things
about lazy languages is that this step is not too difficult.}. We then turn our
attention to the programmer's view of parallelism in a lazy language. Section
\ref{sec:Approaches} explores the current state of the art for parallel
programming (both explicit and implicit parallelism) in a lazy functional
language. We also explore the explicitly parallel techniques because they
inform the way we approach implicit parallelism.
