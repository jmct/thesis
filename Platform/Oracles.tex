\subsection{The Granularity Problem}

We have now discussed how we find the parallelism that is implicit in our
program, but none of the analysis we provide determines whether the safe
parallelism is \emph{worthwhile}. Often static analysis will determine that a
certain structure is \emph{safe} to compute in parallel, but it is very
difficult to know when it is actually of any benefit. Parallelism has overheads
that require the parallel tasks to be substantial enough to make up for the
cost. A \emph{fine-grained} task is unlikely to require more computation than
the cost of sparking and managing the thread, let alone the potential to
interrupt productive threads \citep{hammond2000research, hogen1992automatic}.

One of the central arguments in our work is that static analysis \emph{alone}
is insufficient at finding both the implicit parallelism and determining whether
the introduced parallelism is substantial enough to warrant the overheads.

Our proposal is that the compiler should \emph{run} the program and use the
information gained from running it (even if it only looks at overall execution
time) to \emph{remove} the parallelism that is too fine-grained. By doing this
we shift the burden of the granularity problem away from our static analysis
and onto our search techniques. This way our static analysis is only used to
determine the safe parallel expressions, and not the granularity of the
expressions.

Here we will describe the method by which we identify the \emph{safe}
parallelism in F-Lite programs and arrange for the evaluation of these
expressions in parallel. The \emph{strictness} properties of a function
determine which arguments are definitely needed for the function to terminate,
whereas the \emph{demand} on an argument tells us \emph{how much} of the
argument's structure is needed. \emph{Strategies} are functions that evaluate
their argument's structure to a specific depth. By analysing the program for
strictness and demand information, we can then generate strategies for the
strict arguments to a function and evaluate the strategies in parallel to the
body of the function. The strategies we generate will only evaluate the
arguments to the depth determined by the demand analysis.

\subsection{Introducing \texttt{par}s}
\label{sec:introPar}

While Section \ref{sec:projections} shows how to derive parallel strategies
from projections representing demand, we still require a method to
\emph{introduce} the use of the strategies within the program.  Luckily we can
reuse the results of the projection analysis for this task as well.  The
general approach taken is to apply the generated strategies to \emph{the
strict} arguments of a function. As discussed earlier, the strict arguments are
\emph{safe} for evaluation in parallel. However, there are arguments to
functions that are \emph{clearly} not worthwhile: constants, simple CAFs, etc..
Because of this we introduce an \emph{oracle} that will determine which
arguments should be parallelised.

\subsection*{Example}

Take the famous \verb-fib-:

\begin{verbatim}
    fib :: Int -> Int
    fib 0 = 1
    fib 1 = 1
    fib n = fib (n - 2) + fib (n - 1)
\end{verbatim}

The results of the strictness analysis show us that both arguments to \verb-+-
have the same demand: $ID!$. We therefore evaluate the recursive calls to
\verb-fib- in parallel:

\begin{verbatim}
    fib :: Int -> Int
    fib 0 = 1
    fib 1 = 1
    fib n = let a = fib (n - 2)
                b = fib (n - 1)
            in (s1 a) `par` (s2 b) `seq` a + b
\end{verbatim}

There are two points to consider in the transformed program. One is that by
lifting subexpressions into \verb-let- bindings we preclude the possibility of
certain compiler optimisations. The sharing of values is essential for parallel
strategies to be beneficial.  In particular, thunk elimination becomes more
difficult.

The other point is that we utilise the common technique of combining
\verb-par-s and \verb-seq-s in order to prevent collisions between threads.
This is not always possible and as we will see in \S \ref{sec:conclusion} can
be detrimental.

\hfill$\Box$

\paragraph{Granularity}

It is possible to rely solely on the results of the strictness analysis to
determine which sub-expressions should be evaluated in parallel. However, an
expression being needed does not necessarily mean that evaluating that
expression will be worthwhile. This is known as the \emph{granularity} problem
\citep{hammond2000research}. We use a simple oracle to determine whether a
subexpression should be evaluated in parallel. Recall that our oracle should be
generous in `allowing' subexpressions to be evaluated in parallel. Our
iterative improvement \emph{reduces} the amount of parallelism introduced by
static analysis. As the oracle's only job is to determine whether a
subexpression is `worth' the overhead of parallel evaluation it has the type
\verb+type Oracle = Exp -> Bool+. The two trivial oracles are

\begin{verbatim}
    allYes :: Oracle
    allYes = const True

    allNo :: Oracle
    allNo = const False
\end{verbatim}

\verb-allNo- clearly defeats the purpose of an auto-parallelising compiler, but
\verb-allYes- can serve as a stress-test for the iterative process. The oracle
used in our results returns \verb-True- if the expression contains a non-primitive
function call, \verb-False- otherwise.

\begin{verbatim}
mediumOracle e = or $ map f (universe e)
  where
    f (App (Fun n) as)
        | n `elem` prims = False
        | otherwise      = True
    f _ = False
\end{verbatim}

Here, \verb-universe- takes an expression $e$ and provides a list of all the
valid subexpressions of $e$, reaching the leaf nodes of the AST.

The transformation we apply is simple, for each function application $f \ e_{1}
\dots e_{n}$:

\begin{enumerate}
    \item Gather all the strict argument expressions to a function
    \item Pass each expression to the oracle
    \item Give a name (via let-binding) to each of the oracle-approved expressions
    \item Before calling $f$ spark the application of the derived
        strategy to the appropriate binding
    \item If there are multiple arguments that are oracle approved, ensure that
        the last argument has its strategy applied with \verb-seq-
\end{enumerate}

We now have the necessary mechanisms in place for the \emph{introduction} of
parallelism into a program.
