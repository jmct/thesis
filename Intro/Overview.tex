In this section we will present a high-level overview of our technique.
This will provide the context for our discussion in the subsequent chapters.

\subsection{Compiler Stages}

The majority of our work is in the form of a compiler. Our implementation is
organised into 8 main phases, as follow:

\begin{enumerate}
    \item Parsing
    \item Defunctionalisation
    \item Projection-based Strictness Analysis
    \item Generation of strategies
    \item Placement of \verb-par- annotations
    \item $G$-Code Generation
    \item Execution
    \item Feedback and iteration
\end{enumerate}

Parsing and $G$-Code generation are completely standard. We will therefore
omit discussing those stages of compilation. The focus of this dissertation
is on the static analysis phases (defunctionalisation, strictness analysis,
and the generation of strategies) and the feedback and iteration phase.

\subsection{Our Technique on a Small Example}

The program listed in Figure \ref{fig:tak} is the Tak program benchmark, often used
for testing the performance of recursion in interpreters and code generated by
compilers \citep{ExamplesOfRecursion}.

\begin{figure}
  \input{Blind/TakPhases/Tak.hs}
\caption{Source listing for Tak}
\label{fig:tak}
\end{figure}

After we perform our projection-based strictness analysis, and introduce the
safe \verb-par- annotations, we transform the program into a parallelised
version. The result of this transformation on Tak is listed in Figure
\ref{fig:takParred}.

\begin{figure}[!h]
  \input{Blind/TakPhases/TakParred.hs}
\caption{Source listing for Tak after analysis, transformation, and \texttt{par} placement}
\label{fig:takParred}
\end{figure}

Each strict argument is given a name via a \verb-let- binding. This is so that
any parallel, or \verb-seq-ed, evaluation can be shared between threads. When
there are multiple strict arguments (as is the case for \verb-tak-) we spark
the arguments in left-to-right order except for the last strict argument, which
we \verb-seq-. This is a common technique that is used to avoid potential
collisions \citep{strategies}. Collisions occur when a thread requires the
result of another thread before the result has been evaluated. By ensuring that
one of the arguments is evaluated in the current thread (by using \texttt{seq})
we give the paralell threads more time to evaluate their arguments, lessening
the frequency of collisions.

% TODO: find a place for this, a dicussion of collisions would be good.
%This is best explained through a simple example:
%
%\begin{figure}
%\begin{center}
%\begin{BVerbatim}
%fib :: Int -> Int
%fib 0 = 0
%fib 1 = 1
%fib n = let x = fib (n - 1)
%            y = fib (n - 2)
%        in par x (seq y (x + y))
%\end{BVerbatim}
%\end{center}
%\end{figure}
%
%There are two threads interacting during the execution of \verb-fib-: The
%current thread of execution, $P$ (for parent), and the thread sparked by
%\verb-par x-, $C$ (for child). If the \verb-seq- were a \verb-par-, or absent
%entirely, in \verb-fib- then there is the possibility that $P$ would require
%\verb-x- immediately when evaluating \verb-x + y-. This would cause $P$ to
%block on $C$, awaiting the completion of \verb-x-'s evaluation. By having the
%function use \verb-seq- we ensure that productive work was accomplished even if
%$P$ needs to wait for $C$'s completion.
%
%\hfill$\Box$

%The function \verb-tak- happens to be strict in all three of its arguments.
%Therefore we lift all three arguments into a \verb-let- binding, allowing their
%results to be shared. Then we arrange the parallel evaluation of each of the
%arguments using \verb-par- and \verb-seq- annotations. The \verb-seq-
%annotation is to ensure that \verb-z'- is evaluated in the current thread, so
%that the current thread does not immediately block waiting for \verb-x'- or
%\verb-y'-.
%

While static analysis has determined that \verb-x'- and \verb-y'- can be
evaluated in parallel \emph{safely}, it does not determine whether parallel
evaluation of those expressions is \emph{worthwhile}. This is the crux of the
\emph{granularity problem}. In order to address this issue we take advantage of
two key properties of our \verb-par- annotations:

\begin{enumerate}
    \item Each introduced \verb-par- sparks off a unique subexpression
            in the program's source
    \item The semantics of \verb-par- (as shown in Figure \ref{fig:seqandpar})
            allow us to return its second argument, ignoring the first,
            without changing the semantics of the program as a whole
\end{enumerate}

These two properties allow us to represent the \verb-par-s placed by static
analysis and transformation as a bit string. Each bit represents a specific
\verb-par- in the program's AST. When a \verb-par-'s bit is `on' the \verb-par-
behaves as normal, sparking off its first argument to be evaluated in parallel
and return its second argument. When the bit is `off' the \verb-par- returns
its second argument, ignoring the first.

This allows us to change the \emph{operational} behavior of the program without
altering any of the program's semantics. In other words, we are able to \emph{try}
evaluating subexpressions in parallel, without the risk of introducing behavior
that was not present in the original program.

% Below this is the overview from the IIP paper
% TODO: Merge overviews!

In this section we present the overall picture of our technique. Much of the
discussion will center around the code presented in Figure \ref{sumLast}. In
order to understand the code, it is useful to understand the architecture of the
compiler.

\subsection{A Program Before Iteration}

\begin{figure}[t!]
  \input{Informed/SumPhases/SumEulerProcessed.core}
\caption{Core representation of \texttt{SumEuler} after defunctionalisation, demand
         analysis, and the introduction of initial \texttt{par} sites along
         with their associated strategies.(Auto-generated names have been
         replaced for better readability)}
\label{sumLast}
\end{figure}

The code listed in Figure \ref{sumLast} is the resulting core representation
of the program in Figure \ref{sumOrig} after our analysis and transformations.
Specifically, the program has passed through compiler stages 1-5.

Before we dive into the program itself, note the following points:

\begin{itemize}
    \item We only present the functions that have changed as a result of transformation
    \item We have replaced auto-generated names with easier to read names
    \item Functions ending in `S$N$' are derived strategies
    \item Functions with an underscore in the name are the result of defunctionalisation
\end{itemize}

Taking a look at the program we can see several of the core ideas.

\paragraph{Defunctionalisation}
The application of \verb-map- to \verb-euler- has been replaced by a call to
the specialised \verb-map_euler- function.  We no longer have the functions
\verb-map- or \verb-filter- instead we have specialised versions of these
functions (e.g. \verb-map_euler-)

\paragraph{Introduction of parallelism}
Two calls to \verb-par- have been introduced in the \texttt{main} function. Our
work uses the traditional style for the parallel combinator \citep{strategies}

\begin{verbatim}
    par :: a -> b -> b
    par x y = y
\end{verbatim}

The first argument is \emph{sparked} off to be evaluated in parallel and the
function returns the second argument. This style is what allows us to easily
\emph{switch off} a particular \verb-par- which causes that switched off
\verb-par- to act like \verb-flip const-. This is explored further in
\S\ref{sec:switchPar}.

Each application of \verb-par- introduced by our compiler takes the following
form: \verb-par (s x) e- where \verb-(s x)- is the application of derived
strategy \verb-s- to a variable \verb$x$ and \verb$e$ is an expression containing \verb$x$ as a
free variable.  In a \emph{top-level definition} like \verb-main-, \verb$x$ will be a
name introduced by a \verb-let- expression. For \verb-par-s within the
strategies themselves, \verb$x$ will be a name introduced by case analysis.

\paragraph{Demand Analysis and Strategies}

The compiler has introduced a number of strategies into the program. These
strategies are derived based on the results of a demand analysis. A simple
example from the program is the transformed version of \verb-length-. Because
\verb-+- (for non-lazy integers) requires both arguments to be fully evaluated, it is safe to 
evaluate the arguments to \verb-+- in parallel to the execution of its body.
In order to benefit from the parallel evaluation, the structure must be shared.
The introduction of the name \verb-len- accomplishes this. Because the type
of \verb-len- is \verb-Int- evaluating the expression to WHNF is sufficient to
evaluate the value fully. 

Looking at the body of \verb-euler- where \verb-length- is called we see a
similar pattern. In this case the demand analysis determines that it is
safe the evaluate the \emph{spine} of the list passed to \verb-length-.
The expression is given the name \verb-ys- and the strategy \verb-eulerListS1-
is derived based on this information. Notice that the elements of the list
passed to \verb-eulerListS1- are ignored in its body. 

There are cases where there is a strict demand on an expression but we
do not introduce parallel evaluation of the expression. This can be seen
in the first argument to \verb-+- in the body of \verb-length-. The rules
for which subexpressions are considered \emph{definitely} not worthwhile
are discussed in \S\ref{sec:introPar}.

\paragraph{Iterative Improvement}

Just because an expression is \emph{able} to be evaluated in parallel does not
mean that doing so is beneficial! This is one of the critical problems in
implicit parallelism \citep{hogen1992automatic, hammond2000research,
Jones2009Tuning}. To combat this we run the program as presented in Figure
\ref{sumLast} and collect statistics about the amount of productive work
each \verb-par- is responsible for. The \verb-par-s that do not introduce
a worthwhile amount of parallelism (see discussion in \S\ref{sec:iterate})
are disabled, freeing the program from incurring the overhead of managing
threads for tasks with insufficient granularity \footnote{This can be seen
as a more extreme variation of Clack and Peyton Jones' ``Evaluate and die!''
model of parallelism \citep{clack1986four}: Evaluate \emph{a lot} or die!}.

Earlier we mentioned the \verb-par-s in the bodies of \verb-length- and
\verb-euler-. We picked these examples because while they are safe, they are
not likely to be worthwhile. In the body of \verb-length- the parallel
evaluation of \verb-len- only evaluates what \verb-+- will immediately evaluate
anyway. Giving us no benefit from parallelism. The parallel evaluation of
\verb-ys- in the body of \verb-euler- also suffers from a similar issue.

So why introduce this parallelism? Because the granularity and possible
interference of parallel threads is difficult to know \emph{statically} at
compile time. If we err on the side of generosity with our \verb-par-
annotations we can then use \emph{runtime} profiling to gather information
about the granularity and interference of threads. 

As we would hope, our runtime system does determine that these two \verb-par-s (and some
others) are not worthwhile and disables them, improving performance.

\paragraph{}

Now that we have presented the high-level view of our work we can explore each of
the stages in depth and discuss our reasons for certain design decisions.
